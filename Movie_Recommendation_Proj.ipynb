{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "w1q7fOSnJ5kN",
    "outputId": "d0550dfa-e2f5-451c-eafd-39f684241173",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score,precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpjEkrIEnr8F"
   },
   "source": [
    "# Movie recommendation Project - Through Correlations With Liked Films And The Year Watching\n",
    "\n",
    "In this project we will try to predict which movie should be your next movie, what makes our algorithm more interesting is that it takes into consideration the year you're are watching the movie as movie genres popularity is varying depending on the year.\n",
    "\n",
    "At first, as a POC we will build a recommendation system that is content based filtering, the system will offer generalized recommendations to every user based on the popularity, the genres and the movie's runtime. The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience.\n",
    "\n",
    "Later on, we will try to extend the algorithm with adding demographic filtering based models. Giving a user a more specific recommendation based on his rating on other movies and taking into consideration the popularity of a certian genres in the year he is watching.\n",
    " \n",
    "Some interesting analysis we are hoping to come a cross while working on this:\n",
    "\n",
    "- Genre popularity based on the year, we can tell by that if there was a major event that may cause a specific genre to be more popular\n",
    "- What is the perfect runtime? is there such a thing?\n",
    "- What year is the best year to release movie?\n",
    "- Are people consistently watching the same genre films? e.g. People who watch war, crime and thriller films likely to watch only those genres\n",
    "\n",
    "\n",
    "_Because of low-quality data on old movies, we will **not** ignore movies that were released after the year of watching parameter._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-86265dfdee72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# rating_small_df = pd.read_csv('https://www.dropbox.com/s/526407vecqfcco8/ratings_small.csv?dl=1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimdb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imdb.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmeta_mov_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'movies_metadata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrating_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ratings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# imdb_df = pd.read_csv('https://www.dropbox.com/s/e6qbgjyrlseh2is/imdb.csv?dl=1',error_bad_lines=False,warn_bad_lines=False)\n",
    "# meta_mov_df = pd.read_csv('https://www.dropbox.com/s/j9vxjw3g1s7wqsg/movies_metadata.csv?dl=1')\n",
    "# rating_df = pd.read_csv('https://www.dropbox.com/s/tizyp5zreilielv/ratings.csv?dl=1')\n",
    "# movies_df = pd.read_csv('https://www.dropbox.com/s/oy74gpybw74e4hm/movies.csv?dl=1')\n",
    "# rating_small_df = pd.read_csv('https://www.dropbox.com/s/526407vecqfcco8/ratings_small.csv?dl=1')\n",
    "\n",
    "imdb_df = pd.read_csv('imdb.csv',error_bad_lines=False,warn_bad_lines=False)\n",
    "meta_mov_df = pd.read_csv('movies_metadata.csv')\n",
    "rating_df = pd.read_csv('ratings.csv')\n",
    "movies_df = pd.read_csv('movies.csv')\n",
    "rating_small_df = pd.read_csv('ratings_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb's dataset contains the following features:\n",
    "\n",
    "- tid - IMDb movie id\n",
    "- IMDb Rating + Rating Count - Average ratings the movie recieved + the count of votes recieved\n",
    "- Year - Year of release\n",
    "- One-hot encoding of the genres of each film\n",
    "\n",
    "#### MovieLens's dataset has the following features:\n",
    "\n",
    "- adult - Is it an adult film\n",
    "- budget - How much money was invested\n",
    "- genres - Genres the movie classified to\n",
    "- imdb_id - IMDb's ID\n",
    "- overview - Description of the movie\n",
    "- popularity - A numeric quantity specifying the movie popularity\n",
    "- production_companies - The production house of the movie.\n",
    "- production_countries - The country in which it was produced.\n",
    "- release_date - The date of the movie release\n",
    "- revenue - How much revenue the movie generated worldwide\n",
    "- runtime - How long is the movie in minutes\n",
    "- tagline - Movie's tagline\n",
    "- title - Title of the movie\n",
    "- vote_average - average ratings the movie recieved.\n",
    "- vote_count - the count of votes recieved.\n",
    "\n",
    "##### rating dataset:\n",
    "\n",
    "- userId - A unique value for each user\n",
    "- movieId - A unique movie id in MovieLens\n",
    "- rating - The user rating for that movie\n",
    "- timestamp - The time the movie was rated\n",
    "\n",
    "#### Just a peak at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TMAoqg7i3q0"
   },
   "source": [
    "## Cleaning IMDb dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taking a look at anomlies, years where there is low number of movies,\n",
    "finding the longest sequance of years with movie count higher then 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "8tr25UQU7O4O",
    "outputId": "7a53729d-8ba6-48db-d174-f17758e7005a",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# group by year\n",
    "groupby_year = imdb_df.groupby('year').size().reset_index(name='count').sort_values(['year'])\n",
    "\n",
    "# for each year, if it has sufficient number of movies\n",
    "groupby_year['count'] = groupby_year['count'].apply(lambda x: x < 10)\n",
    "\n",
    "groupby_year.reset_index(inplace=True)\n",
    "\n",
    "# search for sequence of years with 10 >= movies\n",
    "groupby_year = groupby_year.groupby(groupby_year['count'].cumsum()).agg(\n",
    "    {'year':['count', 'min', 'max']})\n",
    "\n",
    "groupby_year.columns = groupby_year.columns.droplevel()\n",
    "\n",
    "# get the longest year sequence in the dataset\n",
    "years_limit = groupby_year[groupby_year['count']==groupby_year['count'].max()]\n",
    "\n",
    "print('our relevant years are bewteen {} to {}'.format(\n",
    "    int(years_limit['min'].values),int(years_limit['max'].values))\n",
    ")\n",
    "\n",
    "# clean movies out of limit\n",
    "imdb_df = imdb_df[(imdb_df['year'] > int(years_limit['min'].values)) & (imdb_df['year'] < int(years_limit['max'].values))]\n",
    "\n",
    "f, axes = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "# Get a feeling of number of movies per year > 10\n",
    "sns.distplot(imdb_df['year'], ax=axes, kde=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjQT1hcoi8Cd"
   },
   "source": [
    "## Cleaning MovieLens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning progress, remove duplicate rows and rows with bad revnue values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sub_sample_size = int(len(rating_df)/30)\n",
    "rating_df_sample = rating_df.sample(n=sub_sample_size, random_state=42)\n",
    "\n",
    "#moveis meta data\n",
    "duplications = len(meta_mov_df['id']) - len(meta_mov_df.drop_duplicates(['id']))\n",
    "print(\"<<<=== There are %s unique movies in our Data and (%s) Duplications ===>>>\" % (len(meta_mov_df['id'].unique()),duplications))\n",
    "print(\"\\n\")\n",
    "# After inspections in df we found duplicated rows so we'll drop the to keep unique values\n",
    "meta_mov_df.drop_duplicates(['id'])\n",
    "\n",
    "#cleaning bad valued in revnue column\n",
    "meta_mov_df.dropna(subset=['revenue'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start to inspcet our data\n",
    "\n",
    "#### Rating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "7Nlei9aZFuix",
    "outputId": "3d201ce2-ecb9-4305-b71e-3ef760d4f051",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's see at what years the user rated films\n",
    "\n",
    "# rating_df inspection of rating \n",
    "rating_df_sample['date'] = rating_df_sample.apply(lambda x: str(datetime.fromtimestamp(x['timestamp']).strftime('%Y-%m-%d')),axis=1)\n",
    "rating_df_sample['release_year'] = pd.to_datetime(rating_df_sample['date']).dt.year\n",
    "\n",
    "# dist of year\n",
    "print('<<<=== lets check out the movies rating years ===>>>')\n",
    "sns.distplot(rating_df_sample['release_year'],rug=True, rug_kws={\"color\": \"g\"},\n",
    "                  kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},\n",
    "                  hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n",
    "                            \"alpha\": 1, \"color\": \"g\"})\n",
    "plt.show()\n",
    "\n",
    "print('<<<=== checking the ratings means distributions ===>>>')\n",
    "ratings_mean = rating_df_sample.groupby(by=['movieId'])['rating'].mean()\n",
    "sns.kdeplot(ratings_mean,shade=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie metadata dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "LF_wKDFDLx3J",
    "outputId": "b6efa130-e435-4b8b-90e8-c954d6078a1d",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# distabition of the popularity values\n",
    "meta_mov_df['popularity'] = pd.to_numeric(meta_mov_df['popularity'],errors='coerce')\n",
    "sns.kdeplot(meta_mov_df['popularity'], shade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the popularity rate isn't distributed normally, we will later on check if popularity has any correlation with a movie being recommended \n",
    "\n",
    "#### Looking at the vote count and vote average\n",
    "\n",
    "As shown in the graph below, we can see that the `vote_average` feature, which represents the average ratings that the movie recieved doesn't corresponds with the `vote_count`.\n",
    "We can see by that there are movies with high vote average but small number of voters, it doesn't necessarily mean that it's better than a movie with a smaller vote average but with high number of voters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(y='vote_count', x='vote_average',data=meta_mov_df[['vote_count','vote_average']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets create our new film Data Set to try to predict a recommended movies\n",
    "\n",
    "What do we consider a recommended movie? A movie with weighted rate above avarage. We think  movie will have a higher probability of being liked by the average audience\n",
    "\n",
    "The model will try to predict if a movie will have an above avarage rate just by the runtime, popularity and the movie's genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing our ratings\n",
    "\n",
    "[based on IMDb's formula](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#)\n",
    "\n",
    "How do you calculate the rank of movies and TV shows on the Top Rated Movies and Top Rated TV Show lists?\n",
    "The following formula is used to calculate the Top Rated 250 titles. This formula provides a true 'Bayesian estimate', which takes into account the number of votes each title has received, minimum votes required to be on the list, and the mean vote for all titles:\n",
    "\n",
    "`weighted rating (WR) = (v ÷ (v+m)) × R + (m ÷ (v+m)) × C`\n",
    "\n",
    "Where:\n",
    "\n",
    "R = average for the movie (mean) = (rating)\n",
    "\n",
    "v = number of votes for the movie = (votes)\n",
    "\n",
    "m = minimum votes required to be listed in the Top Rated list (currently 25,000)\n",
    "\n",
    "C = the mean vote across the whole report\n",
    "\n",
    "Please be aware that the Top Rated Movies Chart only includes theatrical features: shorts, TV movies, miniseries and documentaries are not included in the Top Rated Movies Chart. The Top Rated TV Shows Chart includes TV Series, but not TV episodes or Movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_weighted_rate(row):\n",
    "    m = meta_mov_df['vote_count'].quantile(0.9)\n",
    "    c = meta_mov_df['vote_average'].mean()\n",
    "    v = row['vote_count']\n",
    "    r = row['vote_average']\n",
    "    res = (v / (v+m)) * r + (m / (v+m)) * c\n",
    "    return res\n",
    "\n",
    "meta_mov_df['weighted_rate'] = meta_mov_df.apply(calculate_weighted_rate,axis=1 )\n",
    "\n",
    "print(meta_mov_df['weighted_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "movie_genre_df = meta_mov_df[['id','imdb_id','title','budget','revenue','genres','runtime','release_date','vote_average',\n",
    "                              'vote_count','weighted_rate','popularity']]\n",
    "\n",
    "def get_values_from_genre_json(row, genre):\n",
    "    movies_many_genres = ast.literal_eval(row['genres'])\n",
    "    movies_genres = []\n",
    "    for item in movies_many_genres:\n",
    "        movies_genres.append(item['name'])\n",
    "    if genre in movies_genres:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# extracting the genres\n",
    "genres_list = set()\n",
    "for index, value in movie_genre_df['genres'].iteritems():\n",
    "    movies_genres = ast.literal_eval(value)\n",
    "    for item in movies_genres:\n",
    "        genres_list.add(item['name'])\n",
    "genres_list = list(genres_list)\n",
    "\n",
    "# hot-one encoding for the genres\n",
    "for genre in genres_list:\n",
    "    movie_genre_df[genre] = movie_genre_df.apply(lambda x: get_values_from_genre_json(x, genre), axis=1)\n",
    "\n",
    "movie_genre_df = movie_genre_df.drop(columns=['genres', 'id', 'imdb_id', 'title','release_date','revenue','budget'])\n",
    "movie_genre_df = movie_genre_df[movie_genre_df['popularity'] != 'Beware Of Frost Bites']\n",
    "movie_genre_df = movie_genre_df[movie_genre_df['runtime'].notna()]\n",
    "\n",
    "# here we set the recommended film column based on mean\n",
    "wr_mean = movie_genre_df['weighted_rate'].mean()\n",
    "\n",
    "# drop the columns that weight rate is based on them\n",
    "movie_genre_df['recommended'] = movie_genre_df.apply(lambda x: 'True' if x['weighted_rate']>=wr_mean else 'False' ,axis=1)\n",
    "movie_genre_df.drop(columns=['weighted_rate','vote_average', 'vote_count'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets fit our model\n",
    "\n",
    "At first the recommendation prediciton will be based on the runtime, popularity and genres columns.\n",
    "\n",
    "We will use 3 different models, and we will choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Xs = movie_genre_df.drop('recommended',axis=1)\n",
    "y = movie_genre_df['recommended']\n",
    "X_train,X_test,y_train,y_test = train_test_split(Xs,y,test_size=0.20,random_state=0)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ML_models = {}\n",
    "model_index = ['LR','RF','NN']\n",
    "model_sklearn = [LogisticRegression(solver='liblinear',random_state=0),\n",
    "                 RandomForestClassifier(n_estimators=100,random_state=0),\n",
    "                 MLPClassifier([100]*5,early_stopping=True,learning_rate='adaptive',random_state=0)]\n",
    "\n",
    "model_summary = []\n",
    "\n",
    "for name,model in zip(model_index,model_sklearn):\n",
    "    ML_models[name] = model.fit(X_train,y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    model_summary.append([name,f1_score(y_test,preds,average='weighted'),accuracy_score(y_test,preds),\n",
    "                          roc_auc_score(y_test,model.predict_proba(X_test)[:,1]),])\\\n",
    "    \n",
    "print(ML_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_summary = pd.DataFrame(model_summary,columns=['Name','F1_score','Accuracy','AUC_ROC'])\n",
    "model_summary = model_summary.reset_index()\n",
    "display(model_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small summary\n",
    "\n",
    "We tested 3 different algorithms and found out that the most accurate one to prediect a 'recommneded movie' is MLPClassifier algorithm. This is just by the genres of the film, it's runtime and how popular he was, this is a general recommendation system, not all users like the same genres, like certain runtime our care about the popularity of a movie, this is what we will tackle next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## Collab Filtering POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "meta_mov_rating_df = pd.merge(movies_df,rating_small_df).drop(['genres','timestamp'],axis=1)\n",
    "user_ratings = meta_mov_rating_df.pivot_table(index=['userId'],columns=['title'],values='rating')\n",
    "user_ratings = user_ratings.dropna(thresh=10,axis=1).fillna(0)\n",
    "item_similarity_df = user_ratings.corr(method='pearson')\n",
    "\n",
    "item_similarity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def check_seen(movie,seen_movies):\n",
    "    for item,rating in seen_movies:\n",
    "        if item == movie:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_similar_movies(movie_name,user_rating):\n",
    "    similar_score = item_similarity_df[movie_name]*(user_rating-2.5)\n",
    "    similar_score = similar_score.sort_values(ascending=False)\n",
    "    \n",
    "    return similar_score\n",
    "\n",
    "user_ratings = [(\"Titanic (1997)\",5),(\"Up (2009)\",4),(\"Kung Fu Panda (2008)\",4)]\n",
    "\n",
    "similar_movies = pd.DataFrame()\n",
    "\n",
    "for movie,rating in user_ratings:\n",
    "    similar_movies = similar_movies.append(get_similar_movies(movie,rating),ignore_index=True)\n",
    "\n",
    "all_recommend = similar_movies.sum().sort_values(ascending=False)\n",
    "\n",
    "for movie,score in all_recommend.iteritems():\n",
    "    if not check_seen(movie,user_ratings):\n",
    "        print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Movie Recomindation Proj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}