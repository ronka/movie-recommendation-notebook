{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "w1q7fOSnJ5kN",
    "outputId": "d0550dfa-e2f5-451c-eafd-39f684241173"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpjEkrIEnr8F"
   },
   "source": [
    "# Movie Recommendation Project - Through Correlations With Liked Films And The Year Watching\n",
    "\n",
    "In this project we will try to predict which movie should be your next movie, what makes our algorithm more interesting is that it takes into consideration the year you're are watching the movie as movie genres popularity is varying depending on the year.\n",
    "\n",
    "_Because of low-quality data on old movies, we will **not** ignore movies that were released after the year of watching parameter._\n",
    "\n",
    "### Project outline\n",
    "\n",
    "- Analyzing IMDb's movies dataset to determine which movie genres are popular based on the year\n",
    "- Analyzing MovieLens user rating dataset\n",
    "- (TODO: finish this)\n",
    "\n",
    "At first, as a POC we will try to guess if a movie is recommended or not with supervised ML based on the genre, runtime, revenue, budget and rating.\n",
    "\n",
    "Later on the project we will try to predict to a user based on his previous ratings and with the model we built what is the next movie for him to watch.\n",
    "\n",
    "Some interesting analysis we are hoping to come a cross while working on this:\n",
    "\n",
    "- Genre popularity based on the year, what was the major event in that year that made the popularity of a genre to raise\n",
    "- What is the perfect runtime? is there such a thing?\n",
    "- Is the budget affecting the likelihood of movie success?\n",
    "- If a movie is plausible, what year is the best year to release it?\n",
    "- What was the most profitble year to release a movie?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets load our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb's dataset contains the following features:\n",
    "\n",
    "- tid - IMDb movie id\n",
    "- IMDb Rating + Rating Count - Average ratings the movie recieved + the count of votes recieved\n",
    "- Year - Year of release\n",
    "- One-hot encoding of the genres of each film\n",
    "\n",
    "#### MovieLens's dataset has the following features:\n",
    "\n",
    "- adult - Is it an adult film\n",
    "- budget - How much money was invested\n",
    "- genres - Genres the movie classified to\n",
    "- imdb_id - IMDb's ID\n",
    "- overview - Description of the movie\n",
    "- popularity - A numeric quantity specifying the movie popularity\n",
    "- production_companies - The production house of the movie.\n",
    "- production_countries - The country in which it was produced.\n",
    "- release_date - The date of the movie release\n",
    "- revenue - How much revenue the movie generated worldwide\n",
    "- runtime - How long is the movie in minutes\n",
    "- tagline - Movie's tagline\n",
    "- title - Title of the movie\n",
    "- vote_average - average ratings the movie recieved.\n",
    "- vote_count - the count of votes recieved.\n",
    "\n",
    "We also have a dataset of each user and his rating on MovieLens\n",
    "\n",
    "#### Just a peak at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "imdb_df = pd.read_csv('https://www.dropbox.com/s/e6qbgjyrlseh2is/imdb.csv?dl=1',error_bad_lines=False,warn_bad_lines=False)\n",
    "meta_mov_df = pd.read_csv('https://www.dropbox.com/s/j9vxjw3g1s7wqsg/movies_metadata.csv?dl=1')\n",
    "rating_df = pd.read_csv('https://www.dropbox.com/s/tizyp5zreilielv/ratings.csv?dl=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TMAoqg7i3q0"
   },
   "source": [
    "## Cleaning IMDb dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taking a look at anomlies, years where there is low number of movies,\n",
    "finding the longest sequance of years with movie count higher then 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "8tr25UQU7O4O",
    "outputId": "7a53729d-8ba6-48db-d174-f17758e7005a"
   },
   "outputs": [],
   "source": [
    "# group by year\n",
    "groupby_year = imdb_df.groupby('year').size().reset_index(name='count').sort_values(['year'])\n",
    "\n",
    "# for each year, if it has sufficient number of movies\n",
    "groupby_year['count'] = groupby_year['count'].apply(lambda x: x < 10)\n",
    "\n",
    "groupby_year.reset_index(inplace=True)\n",
    "\n",
    "# search for sequence of years with 10 >= movies\n",
    "groupby_year = groupby_year.groupby(groupby_year['count'].cumsum()).agg(\n",
    "    {'year':['count', 'min', 'max']})\n",
    "\n",
    "groupby_year.columns = groupby_year.columns.droplevel()\n",
    "\n",
    "# get the longest year sequence in the dataset\n",
    "years_limit = groupby_year[groupby_year['count']==groupby_year['count'].max()]\n",
    "\n",
    "print('our relevant years are bewteen {} to {}'.format(\n",
    "    int(years_limit['min'].values),int(years_limit['max'].values))\n",
    ")\n",
    "\n",
    "# clean movies out of limit\n",
    "imdb_df = imdb_df[(imdb_df['year'] > int(years_limit['min'].values)) & (imdb_df['year'] < int(years_limit['max'].values))]\n",
    "\n",
    "f, axes = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "# Get a feeling of number of movies per year > 10\n",
    "sns.distplot(imdb_df['year'], ax=axes, kde=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjQT1hcoi8Cd"
   },
   "source": [
    "## Cleaning MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sample_size = int(len(rating_df)/30)\n",
    "rating_df_sample = rating_df.sample(n=sub_sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data cleaning progress remove of duplicate rows and rows with bad revnue values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moveis meta data\n",
    "duplications = len(meta_mov_df['id']) - len(meta_mov_df.drop_duplicates(['id']))\n",
    "print(\"<<<=== There are %s unique movies in our Data and (%s) Duplications ===>>>\" % (len(meta_mov_df['id'].unique()),duplications))\n",
    "print(\"\\n\")\n",
    "# After inspections in df we found duplicated rows so we'll drop the to keep unique values\n",
    "meta_mov_df.drop_duplicates(['id'])\n",
    "\n",
    "#cleaning bad valued in revnue column\n",
    "meta_mov_df.dropna(subset=['revenue'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start to inspcet our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "7Nlei9aZFuix",
    "outputId": "3d201ce2-ecb9-4305-b71e-3ef760d4f051"
   },
   "outputs": [],
   "source": [
    "# rating_df inspection of rating \n",
    "rating_df_sample['date'] = rating_df_sample.apply(lambda x: str(datetime.fromtimestamp(x['timestamp']).strftime('%Y-%m-%d')),axis=1)\n",
    "rating_df_sample['rate_year'] = rating_df_sample.apply(lambda x: parse(x['date']).year,axis=1)\n",
    "\n",
    "# dist of year\n",
    "print('<<<=== lets check out the movies rating years ===>>>')\n",
    "sns.distplot(rating_df_sample['rate_year'],rug=True, rug_kws={\"color\": \"g\"},\n",
    "                  kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"},\n",
    "                  hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n",
    "                            \"alpha\": 1, \"color\": \"g\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "PjYTylorSI2a",
    "outputId": "c70f19ac-2a5c-4afe-adee-41a2528fa239"
   },
   "outputs": [],
   "source": [
    "# calulate ratings means distributions\n",
    "ratings_mean = rating_df_sample.groupby(by=['movieId'])['rating'].mean()\n",
    "sns.kdeplot(ratings_mean,shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "LF_wKDFDLx3J",
    "outputId": "b6efa130-e435-4b8b-90e8-c954d6078a1d"
   },
   "outputs": [],
   "source": [
    "# Now Lets get started to meet meta our Data\n",
    "meta_mov_df['popularity'] = pd.to_numeric(meta_mov_df['popularity'],errors='coerce')\n",
    "sns.kdeplot(meta_mov_df['popularity'], shade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets set our metric to score the movies rating\n",
    "\n",
    "First of all, we can see that the vote_average feature, which represents the average ratings that the movie recieved.\n",
    "Its not comperable as the vote_count is differnt 10k pepole who their avg vote is e.g 6.6 is not the same for 6.6 for jsut 10 pepole voted for it, so normalization would be needed, as well as getting the ratings them selves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(y='vote_count', x='vote_average',data=meta_mov_df[['vote_count','vote_average']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another good assumption would be to check the movies budget compared to their revenue\n",
    "as we assume that if the revenue is higher then the budget so the rating would be higher for such moive as revenue/budget > 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rev_rate(row):\n",
    "    return float(row['revenue']) / float(row['budget']) if float(row['budget']) > 0 else 1\n",
    "\n",
    "meta_mov_df['revenue_rate'] = meta_mov_df.apply(calc_rev_rate,axis=1)\n",
    "\n",
    "plt.hist(meta_mov_df['revenue_rate'],bins=[0,2/3,4/3,2])\n",
    "plt.title('My title')\n",
    "plt.xlabel('ratio revenue/budget')\n",
    "plt.ylabel('number of movies')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing our ratings\n",
    "\n",
    "[based on IMDb's formula](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV#)\n",
    "\n",
    "How do you calculate the rank of movies and TV shows on the Top Rated Movies and Top Rated TV Show lists?\n",
    "The following formula is used to calculate the Top Rated 250 titles. This formula provides a true 'Bayesian estimate', which takes into account the number of votes each title has received, minimum votes required to be on the list, and the mean vote for all titles:\n",
    "\n",
    "`weighted rating (WR) = (v ÷ (v+m)) × R + (m ÷ (v+m)) × C`\n",
    "\n",
    "Where:\n",
    "\n",
    "R = average for the movie (mean) = (rating)\n",
    "\n",
    "v = number of votes for the movie = (votes)\n",
    "\n",
    "m = minimum votes required to be listed in the Top Rated list (currently 25,000)\n",
    "\n",
    "C = the mean vote across the whole report\n",
    "\n",
    "Please be aware that the Top Rated Movies Chart only includes theatrical features: shorts, TV movies, miniseries and documentaries are not included in the Top Rated Movies Chart. The Top Rated TV Shows Chart includes TV Series, but not TV episodes or Movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_rate(row):\n",
    "    m = meta_mov_df['vote_count'].quantile(0.9)\n",
    "    c = meta_mov_df['vote_average'].mean()\n",
    "    v = row['vote_count']\n",
    "    r = row['vote_average']\n",
    "    res = (v / (v+m)) * r + (m / (v+m)) * c\n",
    "    return res\n",
    "\n",
    "meta_mov_df['Weighted_Rate'] = meta_mov_df.apply(calculate_weighted_rate,axis=1 )\n",
    "print(meta_mov_df['Weighted_Rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets create our new film Data Set to try to predics a recommended Movies\n",
    "\n",
    "\n",
    "First start with parsing the genre column to one-hot encoding for the genre categories.\n",
    "\n",
    "As a POC, let's consider a recommended movie a movie with WR higher than the mean WR in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genre_df = meta_mov_df[['id','imdb_id','title','budget','revenue','genres','runtime','release_date','vote_average',\n",
    "                              'vote_count','Weighted_Rate','popularity']]\n",
    "\n",
    "def get_values_from_genre_json(row, genre):\n",
    "    movies_many_genres = ast.literal_eval(row['genres'])\n",
    "    movies_genres = []\n",
    "    for item in movies_many_genres:\n",
    "        movies_genres.append(item['name'])\n",
    "    if genre in movies_genres:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "genres_list = set()\n",
    "for index, value in movie_gen_df['genres'].iteritems():\n",
    "    movies_genres = ast.literal_eval(value)\n",
    "    for item in movies_genres:\n",
    "        genres_list.add(item['name'])\n",
    "genres_list = list(genres_list)\n",
    "\n",
    "for genre in genres_list:\n",
    "    movie_gen_df[genre] = movie_gen_df.apply(lambda x: get_values_from_genre_json(x, genre), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_gen_df = movie_gen_df.drop(columns=['genres', 'id', 'imdb_id', 'title'])\n",
    "# movie_gen_df = movie_gen_df.dropna(subset=['release_date'])\n",
    "movie_gen_df = movie_gen_df[movie_gen_df['popularity'] != 'Beware Of Frost Bites']\n",
    "#movie_gen_df['release_date'] = movie_gen_df['release_date'].apply(dateutil.parser.parse)\n",
    "\n",
    "#columns = ['release_date']\n",
    "\n",
    "\n",
    "# here we set the recomnded film column based on mean\n",
    "wr_mean = movie_gen_df['Weighted_Rate'].mean()\n",
    "\n",
    "movie_gen_df['recomnded'] = movie_gen_df.apply(lambda x: 'True' if x['Weighted_Rate']>=we_mean else 'False' ,axis=1)\n",
    "print(movie_gen_df['recomnded']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now lets try to cluster some movies together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set concoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode data frame\n",
    "encoded_df = df.copy()\n",
    "for col in columns:\n",
    "    encoded_df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "y_pred = KMeans(n_clusters=2, random_state=0).fit_predict(movie_gen_df)\n",
    "plt.subplot(221)\n",
    "plt.scatter(movie_gen_df, movie_gen_df, c=y_pred)\n",
    "plt.title(\"Incorrect Number of Blobs\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Movie Recomindation Proj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
